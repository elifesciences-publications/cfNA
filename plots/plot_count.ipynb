{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches \n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sequencing_tools.viz_tools import okabeito_palette, \\\n",
    "                        simpsons_palette, \\\n",
    "                        RNA_base_from_picard, \\\n",
    "                        RNA_cov_from_picard, \\\n",
    "                        color_encoder\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from plotting_utils import label_sample, rename_sample, \\\n",
    "                        label_ce, rna_type_ce, label_order, \\\n",
    "                        figure_path\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Arial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genome_rna():\n",
    "    def change_type(x):\n",
    "        if x == 'lncRNA':\n",
    "            return 'Other ncRNA'\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    return pd.read_table('/stor/work/Lambowitz/ref/hg19/new_genes/theoretical/theoretical_base_count.tsv') \\\n",
    "        .assign(grouped_type = lambda d: d.rna_type.map(lambda x: x.strip('b').strip(\"'\"))) \\\n",
    "        .assign(grouped_type = lambda d: d.grouped_type.map(change_type))\\\n",
    "        .query('grouped_type != \"other\"')\\\n",
    "        .assign(base_fraction = lambda d: d.base_fraction / d.base_fraction.sum() * 100)\\\n",
    "        .pipe(pd.pivot_table, columns = 'grouped_type', values='base_fraction', aggfunc=np.sum) \\\n",
    "        .assign(treatment = 'Genome')\\\n",
    "        .set_index('treatment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot count function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_count(ax, feature_only=True, dedup=True):\n",
    "    dedup_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv')\n",
    "\n",
    "\n",
    "    filter_feature = 'No features' if feature_only else ''\n",
    "    dedup_regex = ':dedup:' if dedup else ':all:'\n",
    "    countplot_df = dedup_df \\\n",
    "        .filter(regex = 'type|Qcf|QCF|sim')\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type.str.contains('Y-RNA'), 'Other sncRNA', d.grouped_type))\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type.str.contains(\"vaultRNA|VT|vt\"),'Vault RNA', d.grouped_type))\\\n",
    "        .groupby('grouped_type')\\\n",
    "        .sum() \\\n",
    "        .pipe(lambda d: d[d.columns[~d.columns.str.contains('anti')]])\\\n",
    "        .pipe(lambda d: d[d.columns[d.columns.str.contains(dedup_regex)]]) \\\n",
    "        .reset_index()\\\n",
    "        .pipe(pd.melt, id_vars = ['grouped_type']) \\\n",
    "        .assign(variable = lambda d: d.variable.str.split(':', expand=True).iloc[:,0])\\\n",
    "        .assign(treatment = lambda d: d.variable.map(label_sample)) \\\n",
    "        .groupby(['grouped_type','treatment'], as_index=False)\\\n",
    "        .agg({'value':'sum'}) \\\n",
    "        .query('grouped_type != \"%s\"' %filter_feature)\\\n",
    "        .pipe(lambda d: d[d.treatment.str.contains('Exo|Na|DN|Untre|sim')])\\\n",
    "        .assign(value = lambda d: d.groupby('treatment')['value'].transform(lambda x: 100*x/x.sum()))\\\n",
    "        .pipe(pd.pivot_table, index = 'treatment', \n",
    "             columns = 'grouped_type',\n",
    "             values = 'value')\\\n",
    "        .reset_index() \\\n",
    "        .sort_values('treatment')\\\n",
    "        .set_index('treatment')\\\n",
    "        .pipe(lambda d: d.reindex(sorted(d.columns), axis=1))\n",
    "    \n",
    "    colors = rna_type_ce.transform(countplot_df.columns)\n",
    "    countplot_df\\\n",
    "        .reindex(index=label_order)\\\n",
    "        .plot\\\n",
    "        .bar(stacked=True, \n",
    "             color = colors, \n",
    "              ax = ax,\n",
    "             width = 0.8)\n",
    "    xt = [xt.set_text(xt.get_text()) for xt in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), \n",
    "                       rotation = 70, ha = 'right',\n",
    "                      rotation_mode=\"anchor\")\n",
    "    ax.legend()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], \n",
    "              bbox_to_anchor = (0.9,1), fontsize = 15,\n",
    "             frameon=False)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Read pairs (%)')\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insert size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_insert(ax):\n",
    "    insert_path = '/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/fragment_sizes'\n",
    "    data_files = glob.glob(insert_path + '/*.tsv')\n",
    "    df = {os.path.basename(data_file):pd.read_table(data_file) for data_file in data_files}\n",
    "    df = pd.concat([val.assign(label = key) for key, val in df.items()]) \\\n",
    "        .assign(label = lambda d: d.label.str.replace('.tsv','').str.capitalize())\\\n",
    "        .assign(label = lambda d: np.where(d.label == 'Polya','PolyA-selected', d.label))\\\n",
    "        .sort_values('isize') \\\n",
    "        .query('isize < 300') \\\n",
    "        .assign(size_fraction = lambda d: d.groupby('label')['size_count'].transform(lambda x: 100* x/ x.sum()))\\\n",
    "        .pipe(lambda d: d[d.label.str.contains('Alk|Un|[Ee]xo|All')]) \\\n",
    "        .assign(label = lambda d: d.label.map(label_sample)) \n",
    "    \n",
    "    for lab, lab_df in df.groupby('label'):\n",
    "        ax.plot(lab_df['isize'], \n",
    "                 lab_df['size_fraction'], \n",
    "                 linewidth=3,\n",
    "                 label = lab,\n",
    "                 color = label_ce.encoder[lab])\n",
    "        \n",
    "    ax.legend(title= ' ', \n",
    "             fontsize = 15, \n",
    "             frameon=False, \n",
    "             bbox_to_anchor = (0.6,0.8))\n",
    "    ax.set_xlabel('Read span (nt)')\n",
    "    ax.set_ylabel('Read pairs (%)')\n",
    "    \n",
    "    \n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        label.set_x(label.get_position()[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric_path = '/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/merged_bam/filtered_bam'\n",
    "metrics = glob.glob(metric_path + '/*.RNA_Metrics')\n",
    "metrics = list(filter(lambda x: 'sense' not in x, metrics))\n",
    "\n",
    "def read_metric(metric):\n",
    "    return pd.read_table(metric, skiprows=6, nrows=1)\\\n",
    "        .pipe(pd.melt) \\\n",
    "        .pipe(lambda d: d[d.variable.str.contains('TRANSCRIPT_STRAND_')])\\\n",
    "        .pipe(lambda d: d[d.variable.str.contains('PCT')]) \n",
    "\n",
    "def plot_strand(ax):\n",
    "    strand_df = {os.path.basename(metric).split('.')[0]: read_metric(metric) for metric in metrics}\n",
    "    strand_df = pd.concat([d.assign(samplename = k) for k, d in strand_df.items()])\\\n",
    "        .pipe(lambda d: d[d.samplename.str.contains('[uU]nt|unf|[Aa]lka|[eE]xo|sim|EV')])\\\n",
    "        .assign(samplename = lambda d: d.samplename.map(label_sample))\\\n",
    "        .assign(variable = lambda d: np.where(d.variable.str.contains('R1'), 'Sense','Antisense'))\\\n",
    "        .assign(value = lambda d: d['value'] * 100)\\\n",
    "        .pipe(pd.pivot_table, index='samplename', columns = 'variable', values = 'value')\\\n",
    "        .reindex(index=label_order)\\\n",
    "        .plot.bar(stacked=True, ax = ax, width = 0.8)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 70, ha = 'right',rotation_mode=\"anchor\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Protein-coding bases (%)')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], \n",
    "              bbox_to_anchor = (.9,1), fontsize = 15,\n",
    "             frameon=False)\n",
    "    \n",
    "    \n",
    "def plot_coding_bases(ax):\n",
    "    RNA_base_from_picard(metrics) \\\n",
    "        .assign(var_count = lambda d: d.var_count*100)\\\n",
    "        .pipe(lambda d: d[d.samplename.str.contains('[eE]xo|[uU]nt|unf|[Aa]lka|sim|EV')])\\\n",
    "        .assign(samplename = lambda d: d.samplename.str.split('.',expand=True).iloc[:,0].map(label_sample))\\\n",
    "        .assign(variable = lambda d: d.variable.str.replace('Utr','UTR'))\\\n",
    "        .assign(variable = lambda d: d.variable.str.replace(' bases',''))\\\n",
    "        .pipe(pd.pivot_table, columns = 'variable', index='samplename', values = 'var_count')\\\n",
    "        .reindex(index=label_order)\\\n",
    "        .plot.bar(stacked=True, width = 0.8, color = simpsons_palette(), ax = ax)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 70, ha = 'right',rotation_mode=\"anchor\")\n",
    "    ax.set_ylabel('Protein-coding bases (%)')\n",
    "    ax.set_xlabel('')\n",
    "    ax.legend(title = '', bbox_to_anchor = (1,1))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], bbox_to_anchor = (0.9,1), \n",
    "              fontsize = 15, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-feb7964ca763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max_insert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max_insert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f63177ee3c43>\u001b[0m in \u001b[0;36mplot_insert\u001b[0;34m(ax)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Polya'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PolyA-selected'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stor/work/Lambowitz/cdw2854/src/miniconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/stor/work/Lambowitz/cdw2854/src/miniconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax_insert = fig.add_axes([0,0.6,1,0.45])\n",
    "plot_insert(ax_insert)\n",
    "\n",
    "\n",
    "\n",
    "# lower\n",
    "ax_frag_dist = fig.add_axes([0,0,0.15,0.5])\n",
    "ax_strand = fig.add_axes([0.5,0,0.15,0.5])\n",
    "ax_coding = fig.add_axes([0.95,0,0.15,0.5])\n",
    "\n",
    "\n",
    "#plot_count(ax_frag_dist, feature_only=False)\n",
    "plot_count(ax_frag_dist, feature_only=True)\n",
    "plot_strand(ax_strand)\n",
    "plot_coding_bases(ax_coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (9,5))\n",
    "ax_insert = fig.add_subplot(111)\n",
    "plot_insert(ax_insert)\n",
    "sns.despine()\n",
    "fig.savefig(figure_path + '/insert_plots.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize = (10,8))\n",
    "#ax_frag_dist = fig.add_axes([0,0,0.15,0.5])\n",
    "#ax_frag_dist_feature_only = fig.add_axes([0.5,0,0.15,0.5])\n",
    "#ax_strand = fig.add_axes([1,0,0.15,0.5])\n",
    "#ax_coding = fig.add_axes([1.4,0,0.15,0.5])\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax_frag_dist = fig.add_axes([0,0.52,0.15,0.5])\n",
    "ax_frag_dist_feature_only = fig.add_axes([0.5,0.52,0.15,0.5])\n",
    "ax_strand = fig.add_axes([0,0,0.15,0.5])\n",
    "ax_coding = fig.add_axes([0.5,0, 0.15, 0.5])\n",
    "\n",
    "\n",
    "plot_count(ax_frag_dist, feature_only=False)\n",
    "ax_frag_dist.xaxis.set_visible(False)\n",
    "plot_count(ax_frag_dist_feature_only, feature_only=True)\n",
    "ax_frag_dist_feature_only.xaxis.set_visible(False)\n",
    "plot_strand(ax_strand)\n",
    "plot_coding_bases(ax_coding)\n",
    "#fig.tight_layout()\n",
    "fig.savefig(figure_path + '/fragment_plots.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dedup_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cell_Free_nucleotides/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv')\n",
    "cor_df = np.log(dedup_df\\\n",
    "                    .filter(regex = 'Qcf|QCF')\\\n",
    "                    .filter(regex=\"dedup:sense\") \\\n",
    "                    .pipe(lambda d: d+1))\n",
    "cor_df.columns = rename_sample(cor_df.columns)\n",
    "cor_df = cor_df.corr(method='pearson')\n",
    "p = sns.clustermap(cor_df, cmap = 'viridis')\n",
    "ax = p.ax_heatmap\n",
    "xt = ax.set_xticks(range(cor_df.shape[0]))\n",
    "yt = ax.set_yticks(range(cor_df.shape[1]))\n",
    "xt = ax.set_xticklabels(cor_df.columns[p.dendrogram_col.reordered_ind])\n",
    "yt = ax.set_yticklabels(cor_df.index[p.dendrogram_row.reordered_ind])\n",
    "\n",
    "yt = ax.set_yticks(np.arange(cor_df.shape[1])+0.5)\n",
    "xt = ax.set_xticks(np.arange(cor_df.shape[0])+0.5)\n",
    "\n",
    "ce = color_encoder()\n",
    "ce.fit(cor_df.columns.str.replace(' [0-9]+$',''), \n",
    "                 okabeito_palette())\n",
    "for xt in ax.get_xmajorticklabels():\n",
    "    color = ce.encoder[re.sub(' [0-9]+$','', xt.get_text())]\n",
    "    xt.set_color(color)\n",
    "    \n",
    "for yt in ax.get_ymajorticklabels():\n",
    "    color = ce.encoder[re.sub(' [0-9]+$','', yt.get_text())]\n",
    "    yt.set_color(color)\n",
    "\n",
    "pat = [mpatches.Patch(color=col, label=lab) for lab, col in ce.encoder.items()]\n",
    "ax.legend(handles=pat, bbox_to_anchor = (1.6,0.), fontsize=15)\n",
    "p.fig.text(0.1, 0.86, r\"Pearson's $\\rho$\", rotation = 90, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strand_df = {os.path.basename(metric).split('.')[0]: read_metric(metric) for metric in metrics}\n",
    "pd.concat([d.assign(samplename = k) for k, d in strand_df.items()])\\\n",
    "        .pipe(lambda d: d[d.samplename.str.contains('unf|[Aa]lka')])\\\n",
    "        .assign(samplename = lambda d: np.where(d.samplename.str.contains('[aA]lka'),'Alkaline\\nhydrolysis','DNase\\ntreated'))\\\n",
    "        .assign(variable = lambda d: np.where(d.variable.str.contains('R1'), 'Sense strand','Antisense-strand'))\\\n",
    "        .assign(value = lambda d: d['value'] * 100)\\\n",
    "        .pipe(pd.pivot_table, index='samplename', columns = 'variable', values = 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RNA_base_from_picard(metrics) \\\n",
    "    .pipe(lambda d: d[d.samplename.str.contains('unfr|alka')]) \\\n",
    "    .assign(var_count = lambda d: d.var_count*100)\\\n",
    "    .assign(samplename = lambda d: np.where(d.samplename.str.contains('[Aa]lk'), 'Alkaline hydrolysis', 'DNase-treated'))\\\n",
    "    .pipe(pd.pivot_table, columns = 'variable', index='samplename', values = 'var_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dedup_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv')\n",
    "\n",
    "\n",
    "filter_feature = 'No features' \n",
    "dedup_regex = ':dedup:' \n",
    "dedup_df \\\n",
    "        .filter(regex = 'type|Qcf|QCF|sim')\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type.str.contains('Y-RNA'), 'Other sncRNA', d.grouped_type))\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type.str.contains(\"vaultRNA|VT|vt\"),'Vault RNA', d.grouped_type))\\\n",
    "        .groupby('grouped_type')\\\n",
    "        .sum() \\\n",
    "        .pipe(lambda d: d[d.columns[~d.columns.str.contains('anti')]])\\\n",
    "        .pipe(lambda d: d[d.columns[d.columns.str.contains(dedup_regex)]]) \\\n",
    "        .reset_index()\\\n",
    "        .pipe(pd.melt, id_vars = ['grouped_type']) \\\n",
    "        .assign(variable = lambda d: d.variable.str.split(':', expand=True).iloc[:,0])\\\n",
    "        .assign(treatment = lambda d: d.variable.map(label_sample)) \\\n",
    "        .groupby(['variable','grouped_type','treatment'], as_index=False)\\\n",
    "        .agg({'value':'sum'}) \\\n",
    "        .query('grouped_type != \"%s\"' %filter_feature)\\\n",
    "        .pipe(lambda d: d[d.treatment.str.contains('Exo|Na|DN|Untre|sim')])\\\n",
    "        .assign(value = lambda d: d.groupby('treatment')['value'].transform(lambda x: 100*x/x.sum()))  \\\n",
    "        .query('treatment == \"DNase I\" & grouped_type == \"Protein coding\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_count_with_genome(ax):\n",
    "    dedup_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cell_Free_nucleotides/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv')\n",
    "\n",
    "\n",
    "    countplot_df = dedup_df \\\n",
    "        .filter(regex = 'type|Qcf|QCF')\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "        .groupby('grouped_type')\\\n",
    "        .sum() \\\n",
    "        .pipe(lambda d: d[d.columns[~d.columns.str.contains('anti')]])\\\n",
    "        .pipe(lambda d: d[d.columns[d.columns.str.contains('dedup')]]) \\\n",
    "        .reset_index()\\\n",
    "        .pipe(pd.melt, id_vars = ['grouped_type']) \\\n",
    "        .assign(treatment = lambda d: d.variable.map(label_sample)) \\\n",
    "        .groupby(['grouped_type','treatment'], as_index=False)\\\n",
    "        .agg({'value':'sum'}) \\\n",
    "        .pipe(lambda d: d[d.treatment.str.contains('Exo|Na|DN|Untre')])\\\n",
    "        .assign(value = lambda d: d.groupby('treatment')['value'].transform(lambda x: 100*x/x.sum()))\\\n",
    "        .pipe(pd.pivot_table, index = 'treatment', \n",
    "             columns = 'grouped_type',\n",
    "             values = 'value')\\\n",
    "        .reset_index() \\\n",
    "        .sort_values('treatment')\\\n",
    "        .set_index('treatment')\\\n",
    "        .pipe(lambda d: d.reindex(sorted(d.columns), axis=1))\n",
    "    \n",
    "    colors = rna_type_ce.transform(countplot_df.columns)\n",
    "    countplot_df\\\n",
    "        .pipe(lambda d: pd.concat([d, genome_rna()], sort=True))\\\n",
    "        .reindex(index=np.append('Genome', label_order))\\\n",
    "        .plot\\\n",
    "        .bar(stacked=True, \n",
    "             color = colors, \n",
    "              ax = ax,\n",
    "             width = 0.8)\n",
    "    xt = [xt.set_text(xt.get_text()) for xt in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 70, ha = 'right')\n",
    "    ax.legend()\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], \n",
    "              bbox_to_anchor = (1,1), fontsize = 15,\n",
    "             frameon=False)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Read pairs (%)')\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plot_count_with_genome(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.append('Genome', label_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countplot_df = dedup_df \\\n",
    "        .filter(regex = 'type|Qcf|QCF')\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "        .groupby('grouped_type')\\\n",
    "        .sum() \\\n",
    "        .pipe(lambda d: d[d.columns[~d.columns.str.contains('anti')]])\\\n",
    "        .pipe(lambda d: d[d.columns[d.columns.str.contains('dedup')]]) \\\n",
    "        .reset_index()\\\n",
    "        .pipe(pd.melt, id_vars = ['grouped_type']) \\\n",
    "        .assign(treatment = lambda d: d.variable.map(label_sample)) \\\n",
    "        .groupby(['grouped_type','treatment'], as_index=False)\\\n",
    "        .agg({'value':'sum'}) \\\n",
    "        .pipe(lambda d: d[d.treatment.str.contains('Exo|Na|DN|Untre')])\\\n",
    "        .assign(value = lambda d: d.groupby('treatment')['value'].transform(lambda x: 100*x/x.sum()))\\\n",
    "        .pipe(pd.pivot_table, index = 'treatment', \n",
    "             columns = 'grouped_type',\n",
    "             values = 'value')\\\n",
    "        .reset_index() \\\n",
    "        .sort_values('treatment')\\\n",
    "        .set_index('treatment')\\\n",
    "        .pipe(lambda d: d.reindex(sorted(d.columns), axis=1))\n",
    "countplot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dedup_df \\\n",
    "        .filter(regex = 'id|type|Qcf|QCF')\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "        .query('grouped_type == \"rRNA\"')\\\n",
    "        .groupby('gene_id')\\\n",
    "        .sum() \\\n",
    "        .pipe(lambda d: d[d.columns[~d.columns.str.contains('anti')]])\\\n",
    "        .pipe(lambda d: d[d.columns[d.columns.str.contains('dedup|gene_id')]]) \\\n",
    "        .reset_index()\\\n",
    "        .pipe(pd.melt, id_vars = ['gene_id']) \\\n",
    "        .assign(treatment = lambda d: d.variable.map(label_sample)) \\\n",
    "        .groupby(['gene_id','treatment'], as_index=False)\\\n",
    "        .agg({'value':'sum'}) \\\n",
    "        .pipe(lambda d: d[d.treatment.str.contains('Exo|Na|DN|Untre')])\\\n",
    "        .assign(value = lambda d: d.groupby('treatment')['value'].transform(lambda x: 100*x/x.sum()))\\\n",
    "        .pipe(pd.pivot_table, index = 'treatment', \n",
    "             columns = 'gene_id',\n",
    "             values = 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "28.2 + 62.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6.075118 + 2.731050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dedup_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cell_Free_nucleotides/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv')\n",
    "\n",
    "\n",
    "countplot_df = dedup_df \\\n",
    "        .filter(regex = 'id|type|Q[cC][fF][0-9]+')\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "        .assign(grouped_type = lambda d: np.where(d.grouped_type == \"caultRNA\", 'Vault RNA', d.grouped_type))\\\n",
    "        .pipe(lambda d: d[d.columns[~d.columns.str.contains('anti')]])\\\n",
    "        .pipe(lambda d: d[d.columns[d.columns.str.contains('id|type|dedup')]]) \\\n",
    "        .pipe(lambda d: d[d.grouped_type.str.contains('sno|tRN|vault|sncRNA|mi|snR')]) \\\n",
    "        .assign(sum_count = lambda d: d.iloc[:,3:].sum(axis=1)) \\\n",
    "        .groupby(['grouped_type'], as_index=False)\\\n",
    "        .apply(lambda d: d.nlargest(10, 'sum_count'))\\\n",
    "        .reset_index()\n",
    "#        .pipe(pd.melt, id_vars = ['grouped_type']) \\\n",
    "#        .assign(treatment = lambda d: d.variable.map(label_sample)) \\\n",
    "#        .pipe(lambda d: d[d.treatment.str.contains('Exo|Na|DN|Untre')])\n",
    "countplot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long_phos = pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv')\\\n",
    "    .filter(regex='id|name|grouped|L[12]|Frag|Phos|Qcf11|Qcf6') \\\n",
    "    .filter(regex = 'id|name|grouped|dedup:sense')\\\n",
    "    .rename(columns = lambda x: x.split(':')[0])\\\n",
    "    .rename(columns = {'Qcf_Frag3_R1_001':'Qcf_Phos1_R1_001',\n",
    "                      'Qcf_Phos1_R1_001': 'Qcf_Frag3_R1_001'})\\\n",
    "    .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "long_phos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "pdf = long_phos\\\n",
    "    .drop('Qcf_Frag3_R1_001',axis=1)\\\n",
    "    .pipe(lambda d: d[~d.grouped_type.isin(['a'])]) \\\n",
    "    .assign(grouped_type = lambda d: np.where(d.grouped_type == \"rDNA\", 'rRNA', d.grouped_type))\\\n",
    "    .assign(grouped_type = lambda d: np.where(d.grouped_type == \"vaultRNA\", 'Vault RNA', d.grouped_type))\\\n",
    "    .drop(['gene_id','gene_name'], axis=1)\\\n",
    "    .groupby('grouped_type') \\\n",
    "    .sum() \\\n",
    "    .transform(lambda d: d/d.sum(axis=0) * 100) \\\n",
    "    .transpose()\\\n",
    "    .reset_index() \\\n",
    "    .assign(index = lambda d: rename_sample(d['index']))\\\n",
    "    .set_index('index')\\\n",
    "    .loc[['DNase I 1', 'DNase I 2', 'DNase I + Phosphatase 1', \n",
    "          'Fragmented 1', 'Fragmented 2', \n",
    "         'PolyA-selected 1', 'PolyA-selected 2'],:]\n",
    "pdf.plot.bar(stacked=True, ax = ax, color = rna_type_ce.transform(pdf.columns))\n",
    "ax.legend(bbox_to_anchor = (1,1), frameon=False, fontsize=15)\n",
    "sns.despine()\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=70, rotation_mode = 'anchor', ha = 'right')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Read pairs (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = long_phos \\\n",
    "    .pipe(lambda d: d[d.columns[~d.columns.str.contains('L[12]')]])\\\n",
    "    .query('grouped_type == \"rDNA\"') \\\n",
    "    .set_index('name')\\\n",
    "    .drop(['id','grouped_type'], axis=1) \\\n",
    "    .transform(lambda d: d/d.sum(axis=0)) \\\n",
    "    .transpose()\\\n",
    "    .plot.bar(color=simpsons_palette(), stacked=True)\n",
    "ax.set_ylabel('Enrichment (relative to 5S_rRNA)')\n",
    "ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.apply(lambda d: d/d.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long_phos\\\n",
    "    .query('grouped_type==\"Other ncRNA\"')\\\n",
    "    .pipe(lambda d: d[d.iloc[:,3:].sum(axis=1)>0]) \\\n",
    "    .sort_values('Qcf_Frag3_R1_001', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/fragment_sizes/all.tsv') \\\n",
    "    .sort_values('isize')\\\n",
    "    .query('isize<400')\\\n",
    "    .plot('isize','size_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dedup_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv') \\\n",
    "    .filter(regex='grouped|Q[cC][fF][0-9]+')\\\n",
    "    .filter(regex='grouped|:dedup:sense') \\\n",
    "    .query('grouped_type != \"No features\"')\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Y-RNA\",'vaultRNA','miRNA','snoRNA']), 'Other sncRNA', d.grouped_type))\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Antisense\"]), 'Other ncRNA', d.grouped_type))\\\n",
    "    .groupby('grouped_type', as_index=False)\\\n",
    "    .sum()\\\n",
    "    .assign(row_sum = lambda d: d.sum(axis=1)) \\\n",
    "    .assign(color = lambda d: rna_type_ce.transform(d['grouped_type']))\\\n",
    "    .assign(row_sum = lambda d: d.row_sum.transform(lambda x: x/x.sum()))\n",
    "dedup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pie_df = dedup_df\\\n",
    "    .assign(grouped_type = lambda d: list(map(lambda g, f: g + '\\n(%.1f%s)' %(f*100,'%'), d.grouped_type, d.row_sum))) \\\n",
    "    .set_index('grouped_type') \\\n",
    "    .assign(explode = lambda d: np.where(d.row_sum < 0.01, 1/d.row_sum/400, 0)) \\\n",
    "    .assign(explode = lambda d: d.explode.clip(0,1.3)) \\\n",
    "    .sort_values('row_sum') \n",
    "p = pie_df.plot.pie(y = 'row_sum', colors = pie_df.color, explode = pie_df.explode.tolist(), figsize=(8,8))\n",
    "p.legend().set_visible(False)\n",
    "p.set_ylabel('')\n",
    "plt.savefig(figure_path + '/RNA_pie.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pie_df[pie_df.columns[~pie_df.columns.str.contains('[Qq][cC][fF]')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snc_ce = color_encoder()\n",
    "snc_ce.encoder = {'tRNA': '#f4df42',\n",
    "                 'snRNA': '#f49b00',\n",
    "                 'snoRNA': '#ad1414',\n",
    "                 'miRNA': '#56dd44',\n",
    "                 '7SL': '#6274c1',\n",
    "                 '7SK': 'black',\n",
    "                 'Y RNA': '#f990ec',\n",
    "                 'Other sncRNA': '#00b9bc',\n",
    "                 'Vault RNA': '#f990ec'}\n",
    "\n",
    "def rename_snc(x): \n",
    "    if x == 'Y-RNA':\n",
    "        return 'Y RNA'\n",
    "    elif x == 'misc_RNA':\n",
    "        return 'Other sncRNA'\n",
    "    elif x== 'vaultRNA': \n",
    "        return 'Vault RNA'\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "\n",
    "snc_df = pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv') \\\n",
    "    .filter(regex='id|type|grouped|Q[cC][fF][0-9]+')\\\n",
    "    .filter(regex='id|type|grouped|:dedup:sense') \\\n",
    "    .query('grouped_type != \"No features\"')\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Y-RNA\",'vaultRNA','miRNA','snoRNA']), 'Other sncRNA', d.grouped_type))\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Antisense\"]), 'Other ncRNA', d.grouped_type))\\\n",
    "    .pipe(lambda d: d[d.grouped_type.isin(['tRNA', \"Other sncRNA\"])]) \\\n",
    "    .assign(gene_id = lambda d: np.where(d.gene_type == \"tRNA\", \n",
    "                                        np.where(~d.gene_id.str.contains('MT'),\n",
    "                                                d.gene_id.str.extract('(^TR[A-Za-z]+-[ACTGN]{3})', expand=False),\n",
    "                                                d.gene_id.str.extract('(^MT-[A-Z]{2})', expand=False)),\n",
    "                                        d.gene_id)) \\\n",
    "    .pipe(lambda d: d[~d.gene_id.str.contains('MT|-ATA')])\\\n",
    "    .groupby(['gene_type','gene_id','grouped_type'], as_index=False)\\\n",
    "    .sum()\\\n",
    "    .assign(row_sum = lambda d: d.filter(regex='^[Qq][cC][fF]').sum(axis=1))\\\n",
    "    .filter(regex = 'id|type|row_sum') \\\n",
    "    .query('row_sum > 0') \\\n",
    "    .assign(dummy = 1)\\\n",
    "    .groupby(['gene_type'], as_index=False)\\\n",
    "    .agg({'row_sum': 'sum',\n",
    "         'dummy':'sum'}) \\\n",
    "    .assign(gene_type = lambda d: d.gene_type.map(rename_snc))\\\n",
    "    .assign(color = lambda d: d['gene_type'].map(snc_ce.encoder))\n",
    "snc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('axes', labelsize=40)\n",
    "\n",
    "\n",
    "pie_df = snc_df\\\n",
    "    .assign(grouped_type = lambda d: list(map(lambda g, f: g + '\\n(%i%s)' %(f,''), d.gene_type, d.dummy))) \\\n",
    "    .set_index('grouped_type') \\\n",
    "    .assign(row_sum = lambda d: d.row_sum/(d.row_sum.sum()))\\\n",
    "    .assign(explode = lambda d: np.where(d.row_sum < 0.5, 1/d.row_sum/600, 0)) \\\n",
    "    .assign(explode = lambda d: d.explode.clip(0,0)) \\\n",
    "    .sort_values('row_sum', ascending=False) \n",
    "p = pie_df.plot.pie(y = 'row_sum', colors = pie_df.color, explode = pie_df.explode.tolist(), figsize=(8,8))\n",
    "p.legend().set_visible(False)\n",
    "p.set_ylabel('')\n",
    "plt.savefig(figure_path + '/sncRNA_pie.eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv') \\\n",
    "    .filter(regex='id|type|grouped|Q[cC][fF][0-9]+')\\\n",
    "    .filter(regex='id|type|grouped|:dedup:sense') \\\n",
    "    .query('grouped_type != \"No features\"')\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Y-RNA\",'vaultRNA','miRNA','snoRNA']), 'Other sncRNA', d.grouped_type))\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Antisense\"]), 'Other ncRNA', d.grouped_type))\\\n",
    "    .pipe(lambda d: d[d.grouped_type.isin(['tRNA', \"Other sncRNA\"])]) \\\n",
    "    .assign(gene_id = lambda d: np.where(d.gene_type == \"tRNA\", \n",
    "                                        np.where(~d.gene_id.str.contains('MT'),\n",
    "                                                d.gene_id.str.extract('(^TR[A-Za-z]+-[ACTGN]{3})', expand=False),\n",
    "                                                d.gene_id.str.extract('(^MT-[A-Z]{2})', expand=False)),\n",
    "                                        d.gene_id)) \\\n",
    "    .groupby(['gene_type','gene_id','grouped_type'], as_index=False)\\\n",
    "    .sum()\\\n",
    "    .assign(row_sum = lambda d: d.filter(regex='^[Qq][cC][fF]').sum(axis=1))\\\n",
    "    .query('gene_type == \"tRNA\"')\\\n",
    "    .assign(mt = lambda d: np.where(d.gene_id.str.contains('MT'), 'is_mt','not_mt'))\\\n",
    "    .groupby('mt')\\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "codons = [''.join(it) for it in product(list('ACTG'), repeat = 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anti = pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv') \\\n",
    "    .filter(regex='id|type|grouped|Q[cC][fF][0-9]+')\\\n",
    "    .filter(regex='id|type|grouped|:dedup:sense') \\\n",
    "    .query('grouped_type != \"No features\"')\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Y-RNA\",'vaultRNA','miRNA','snoRNA']), 'Other sncRNA', d.grouped_type))\\\n",
    "    .assign(grouped_type = lambda d: np.where(d['grouped_type'].isin([\"Antisense\"]), 'Other ncRNA', d.grouped_type))\\\n",
    "    .pipe(lambda d: d[d.grouped_type.isin(['tRNA', \"Other sncRNA\"])]) \\\n",
    "    .assign(gene_id = lambda d: np.where(d.gene_type == \"tRNA\", \n",
    "                                        np.where(~d.gene_id.str.contains('MT'),\n",
    "                                                d.gene_id.str.extract('(^TR[A-Za-z]+-[ACTGN]{3})', expand=False),\n",
    "                                                d.gene_id.str.extract('(^MT-[A-Z]{2})', expand=False)),\n",
    "                                        d.gene_id)) \\\n",
    "    .pipe(lambda d: d[~d.gene_id.str.contains('MT')])\\\n",
    "    .groupby(['gene_type','gene_id','grouped_type'], as_index=False)\\\n",
    "    .sum()\\\n",
    "    .assign(row_sum = lambda d: d.filter(regex='^[Qq][cC][fF]').sum(axis=1))\\\n",
    "    .filter(regex = 'id|type|row_sum') \\\n",
    "    .query('row_sum > 0') \\\n",
    "    .query('gene_type == \"tRNA\"') \\\n",
    "    .assign(anticodon = lambda d: d.gene_id.str.split('-',expand=True).iloc[:,1]) \\\n",
    "    .filter({'anticodon','gene_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_anti = 'AAC,AAG,AAT,ACG,AGA,AGC,AGG,AGT,ATA,'\\\n",
    "        'CAA,CAC,CAG,CAT,CCA,CCC,CCG,CCT,CGA,CGC,CGG,CGT,CTC,CTG,CTT,GAA,GAT,GCA,GCC,GCT,GTA,GTC,GTG,'\\\n",
    "            'GTT,TAA,TAC,TAG,TAT,TCA,TCC,TCG,TCT,TGA,TGC,TGG,TGT,TTC,TTG,TTT'.split(',')\n",
    "len(all_anti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anti.query('anticodon == \"CAT\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_table('/stor/work/Lambowitz/cdw2854/cfNA/tgirt_map/Counts/all_counts/spreaded_all_counts.tsv') \\\n",
    "    .filter(regex='id|type|grouped|Q[cC][fF][0-9]+')\\\n",
    "    .filter(regex='id|type|grouped|:dedup:sense') \\\n",
    "    .query('grouped_type == \"Other ncRNA\"') \\\n",
    "    .query('gene_type == \"lincRNA\"')\\\n",
    "    .assign(gene_expr = lambda d: d.iloc[:, 3:].sum(axis=1))\\\n",
    "    .query('gene_expr > 10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda3",
   "language": "python",
   "name": "miniconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
